#### 目录说明
- train
  - environment
  - others
  - textProcess 语料库预处理
    - stop_words.txt 停用词
    - weibo_corpus_use_for_get_word2vec.txt 是未分词的语料库
    - cut_clean_corpus 是处理好了的语料库 包括分词、去停用词、去标点
    - corpus_word2vec 是存储词向量的
    - xml_parser.py 
      * 解析xml为纯文本
      * 解析xml为字典 
  - ./ 根目录 
  - README.md
  
#### 其它说明